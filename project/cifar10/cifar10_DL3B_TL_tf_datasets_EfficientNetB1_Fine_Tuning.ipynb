{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alemskdlt/dl02/blob/main/project/cifar10/cifar10_DL3B_TL_tf_datasets_EfficientNetB1_Fine_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVD6Jhk-SgvR"
      },
      "source": [
        "# Transfer learning\n",
        "- cifar10 dataset from tensorflow_datasets\n",
        "- ConvNet: EfficientNetB1\n",
        "\n",
        "> https://www.tensorflow.org/api_docs/python/tf/keras/applications/efficientnet/EfficientNetB1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5Dbt73ZSR24"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fs0VSApwVk9N"
      },
      "source": [
        "## Load cifar10 using tensorflow_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xe_3a7_Sskb"
      },
      "outputs": [],
      "source": [
        "# CFAR-10 데이터 세트를 적재한다. (tensorflow_datasets)\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "Batch_size = 64\n",
        "# \n",
        "dataset_name = \"cifar10\"  # change the name of the dataset \n",
        "# PrefetchDataset : BatchDataSet => (None, 32, 32, 3)\n",
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    dataset_name, \n",
        "    split=[\"train\", \"test\"], \n",
        "    with_info=True, \n",
        "    batch_size=Batch_size,  # preset mini-batch\n",
        "    as_supervised=True\n",
        ")\n",
        "\n",
        "NUM_CLASSES = ds_info.features[\"label\"].num_classes\n",
        "print(NUM_CLASSES)\n",
        "label_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "print(ds_train)  # PrefetchDataset\n",
        "# PrefetchDataset element_spec=(TensorSpec(shape=(None, 32, 32, 3)\n",
        "# Batch preset?\n",
        "\n",
        "for i, (image, label) in enumerate(ds_train.take(1)):\n",
        "    print(i, image.shape, label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-HvM_941boV"
      },
      "outputs": [],
      "source": [
        "print(ds_train)\n",
        "print(ds_info)\n",
        "ds_info.features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDaxZCsqTu_E"
      },
      "outputs": [],
      "source": [
        "# Show samples\n",
        "# _ = tfds.show_examples(ds_train, ds_info)\n",
        "IMG_SIZE = 128 #120 #240  # for Transfer Learning using EfficientNetB1\n",
        "size = (IMG_SIZE, IMG_SIZE)\n",
        "ds_train = ds_train.map(lambda image, label: (tf.image.resize(image, size), label))\n",
        "ds_test = ds_test.map(lambda image, label: (tf.image.resize(image, size), label))\n",
        "\n",
        "print(len(ds_train),len(ds_test))\n",
        "\n",
        "str(ds_train)  # MapDataset\n",
        "for i, (image, label) in enumerate(ds_train.take(1)):\n",
        "    print(i, image.shape, label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bl4QnEWgKuAY"
      },
      "outputs": [],
      "source": [
        "50000/64,10000/64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZn7B50sLD_w"
      },
      "outputs": [],
      "source": [
        "str(ds_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pV_K07aVT1W0"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# Visualizing the dataset\n",
        "#\n",
        "# The following code shows the first 9 images with their labels.\n",
        "\n",
        "print(\"=\"*25, 'Train dataset', \"=\"*25)\n",
        "# figure 크기를 조절합니다.\n",
        "plt.figure(figsize=(6, 6))\n",
        "# 배치 하나를 가져옵니다.\n",
        "for images, labels in ds_train.take(1):    # Make a batch of images & labels\n",
        "    print(images.shape)\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))  # tensor2numpy array: tensor.numpy()\n",
        "        # plt.title(label_names[int(labels[i])])\n",
        "        plt.title(str(labels[i].numpy()) + \", \" + label_names[int(labels[i])])\n",
        "        plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "print(\"=\"*25, 'Test dataset', \"=\"*25)\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "for images, labels in ds_test.take(1):    # Make a batch of images & labels\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        # plt.title(label_names[int(labels[i])])\n",
        "        plt.title(str(labels[i].numpy()) + \", \" + label_names[int(labels[i])])\n",
        "        plt.axis(\"off\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Gp7c52NT_YX"
      },
      "source": [
        "## Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6GtqHK-T6bc"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# Data augmentation\n",
        "#\n",
        "from tensorflow.keras import layers\n",
        "tf.get_logger().setLevel('ERROR')  # Clear warnings in data augmentation\n",
        "# Create a data augmentation with horizontal flipping, rotations, zooms\n",
        "data_augmentation = keras.Sequential([\n",
        "  layers.RandomFlip(\"horizontal\"),\n",
        "  layers.RandomRotation(factor=0.1),\n",
        "  layers.RandomZoom(0.1),\n",
        "  # layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
        "  layers.RandomHeight(0.1),\n",
        "  layers.RandomWidth(0.1),\n",
        "  # layers.Rescaling(1./255) # keep for ResNet50V2, remove for EfficientNetB0\n",
        "], name =\"data_augmentation\")\n",
        "\n",
        "# Plot the augmented images\n",
        "plt.figure(figsize=(6,6))\n",
        "image_idx = np.random.randint(10)   # 0~ 9\n",
        "for images, labels in ds_train.take(1):    # Make a batch of images & labels\n",
        "    print(labels,images.shape)\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        aug_img = data_augmentation(tf.expand_dims(images[image_idx], axis=0))\n",
        "        print(aug_img.shape)\n",
        "        plt.imshow(aug_img[0].numpy().astype(\"uint8\"))\n",
        "        plt.title(\"{}\".format(label_names[labels[image_idx]]))\n",
        "        plt.axis(\"off\")\n",
        "    break\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "image_idx = np.random.randint(10)   # 0~ 9\n",
        "for images, labels in ds_test.take(1):    # Make a batch of images & labels\n",
        "    print(labels,images.shape)\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        aug_img = data_augmentation(tf.expand_dims(images[image_idx], axis=0))\n",
        "        print(aug_img.shape)\n",
        "        plt.imshow(aug_img[0].numpy().astype(\"uint8\"))\n",
        "        plt.title(\"{}\".format(label_names[labels[image_idx]]))\n",
        "        plt.axis(\"off\")\n",
        "    break\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxpuVHB_1boX"
      },
      "source": [
        "# Model: Transfer learning\n",
        "- ## EfficientNet V1 : EfficientNetB1\n",
        "---\n",
        "> ### EfficientNet-B1은 EfficientNetV1 계열의 모델 중 하나로, Compound Scaling 방법을 사용해 기초 모델인 EfficientNet-B0에 비해 성능과 효율성이 향상된 모델입니다.  ( from wrtn.ai )\n",
        "\n",
        "### EfficientNet-B1의 주요 특징은 다음과 같습니다:\n",
        "\n",
        "1. **가변성**: EfficientNet-B1은 기본 이미지 해상도를 240x240으로 지원하며, 따라서 이보다 크거나 작은 이미지를 처리하기에도 적합합니다.\n",
        "2. **상대적으로 작은 모델**: 이 모델은 실전 상황에서 쉽게 배포할 수 있는 모델을 제공하며, 컴퓨터 자원에 큰 부담을 주지 않습니다. 그럼에도 불구하고, 비슷한 크기의 다른 모델에 비해 더 높은 성능을 보입니다.\n",
        "3. **복합 스케일링**: EfficientNet-B1은 모델의 깊이, 너비, 그리고 해상도를 각각 조절하는 구조로, 이미지 입력 크기와 파라미터 수를 유연하게 조정할 수 있도록 설계되어 있습니다.\n",
        "4. **사전 훈련 가중치**: EfficientNet-B1은 ImageNet 데이터셋에서 이미 학습된 가중치를 제공합니다. 이렇게 전이학습에 사용할 수 있는 사전 훈련된 가중치가 있기 때문에 비교적 적은 양의 데이터셋으로부터도 높은 성능의 모델을 학습할 수 있습니다.\n",
        "\n",
        "- **EfficientNet-B1은 다양한 이미지 분류 작업에 효과적으로 사용될 수 있으며, 소량의 컴퓨팅 파워와 메모리를 사용하여도 높은 성능을 낼 수 있습니다.**\n",
        "- **전이학습에 유용한 이 모델은 다양한 사례에서 활용될 수 있어, 인기 있는 모델 중 하나** 입니다.\n",
        "---\n",
        "> EfficientNetV2는 EfficientNet에서 개선된 모델 계열로서, 합성곱신경망의 성능과 크기의 균형을 더욱 잘 맞추도록 설계되었습니다. EfficientNetV2 모델 계열에는 학습 및 구현을 위한 여러 가지 사이즈와 구성의 모델이 포함되어 있습니다.\n",
        "\n",
        "## EfficientNetV2 모델 계열에는 다음과 같은 모델들이 있습니다:\n",
        "\n",
        "- EfficientNetV2-B0: 가장 기본 모델로, 파라미터 수가 약 55M 미만입니다. 이 모델은 기본 디자인을 시작점으로 삼아 이후에 나오는 모델들의 성능과 크기를 조절합니다.\n",
        "- EfficientNetV2-B1: 약 78M 개의 파라미터를 가진 중간 크기의 모델로, 입력 이미지의 크기는 240×240입니다.\n",
        "- EfficientNetV2-B2: 약 90M 개의 파라미터를 가진 조금 더 큰 모델로, 입력 이미지의 크기는 260×260입니다.\n",
        "- EfficientNetV2-B3: 약 122M 개의 파라미터를 가진 크고 강력한 모델로, 입력 이미지의 크기는 300×300입니다.\n",
        "- EfficientNetV2S: 여러 모델 중 가장 작은 모델로, 입력 이미지의 크기가 224×224이고, 모델 파라미터의 수는 약 22M입니다.\n",
        "- EfficientNetV2M: 중간 크기의 모델로, 약 305M 개의 파라미터를 가지고 있으며 입력 이미지의 크기는 112×112입니다.\n",
        "- EfficientNetV2L: 중간 크기의 모델보다 큰 모델로, 약 400M 개의 파라미터를 가지고 있으며 입력 이미지의 크기는 128×128입니다.\n",
        "> 각 EfficientNetV2 모델은 다양한 요구사항과 자원에 맞게 적합한 크기와 성능을 가지고 있습니다. 이 모델들은 기존의 EfficientNet 계열보다 높은 성능과 효율성을 달성하며, 다양한 작업에서 좋은 결과를 낼 수 있습니다. 그리고, EfficientNetV2 모델들은 이미지넷에서 미리 훈련된 가중치를 가지고 있으므로, 전이 학습에서도 높은 성능을 보입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "euCcaNwAT-Bk"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# Transfer learning => Fine Tuning\n",
        "#\n",
        "## Using the model EfficientNetB1 for the first experiment with all the layers trainable \n",
        "## Creating the model \n",
        "\n",
        "from tensorflow.keras.applications.efficientnet import EfficientNetB1\n",
        "# base_model = EfficientNetV2S(include_top=False, weights='imagenet', input_shape=(224, 224, 3), pooling='max')\n",
        "base_model = tf.keras.applications.EfficientNetB1(include_top = False, weights='imagenet')\n",
        "base_model.trainable = True # Full Training\n",
        "\n",
        "# Fine-tune from this layer onwards\n",
        "fine_tune_at = 235  # half of the whole layers\n",
        "\n",
        "#  Fine-tuning after layer_number larger than 235\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable =  False\n",
        "\n",
        "for layer_number, layer in enumerate(base_model.layers):\n",
        "    print(layer_number, layer.name, layer.trainable, end=\", \")\n",
        "  \n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  layers.Input(shape=(IMG_SIZE,IMG_SIZE,3),name='input_layer'),\n",
        "  # layers.Rescaling(1./255),\n",
        "  data_augmentation,\n",
        "  # Fine Tuning\n",
        "  base_model,\n",
        "  layers.GlobalMaxPooling2D(name = \"global_max\"),\n",
        "  # FCN\n",
        "  layers.Dense(128,activation='relu'),\n",
        "  layers.Dense(10,activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), \n",
        "              loss = 'sparse_categorical_crossentropy', \n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqewzhnPOyeP"
      },
      "outputs": [],
      "source": [
        "# Check the input and output of base_model\n",
        "ix=layers.Input(shape=(IMG_SIZE,IMG_SIZE,3))\n",
        "print(base_model(ix))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0YSrzlzUmvi"
      },
      "outputs": [],
      "source": [
        "keras.utils.plot_model(model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voXEyb2LVZuk"
      },
      "source": [
        "## Building the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lV_RaiGUP-y"
      },
      "outputs": [],
      "source": [
        "# Building the Model\n",
        "# Inspecting the train_data\n",
        "ds_train\n",
        "# Setting up the callbacks\n",
        "# Setup EarlyStopping callback to stop training if model's val_loss doesn't improve for 3 epochs\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", # watch the val loss metric\n",
        "                                                  patience=5) # if val loss decreases for 5 epochs in a row, stop training\n",
        "# Creating learning rate reduction callback\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",  \n",
        "                                                 factor=0.25, # multiply the learning rate by 0.2 (reduce by 4x)\n",
        "                                                 patience=3,\n",
        "                                                 verbose=1, # print out when learning rate goes down \n",
        "                                                 min_lr=1e-7)\n",
        "\n",
        "## Check the summary\n",
        "for no, layer in enumerate(model.layers):\n",
        "  print(no, layer.trainable)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPBiIFTIVQ-6"
      },
      "source": [
        "##  Training model using augmentated dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eCDL2_xU0dC"
      },
      "outputs": [],
      "source": [
        "#\n",
        "######################################################\n",
        "# Training model using augmentated data\n",
        "######################################################\n",
        "#\n",
        "%%time\n",
        "history = model.fit(ds_train, \n",
        "                    epochs=100, \n",
        "                    steps_per_epoch = len(ds_train), \n",
        "                    validation_data = ds_test,\n",
        "                    validation_steps = len(ds_test), # batchSize,\n",
        "                    callbacks = [early_stopping, reduce_lr])\n",
        "\n",
        "#\n",
        "model.evaluate(ds_test)\n",
        "# loss: 0.1658 - accuracy: 0.9595\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7E14JzCVHR-"
      },
      "source": [
        "## Plot of learning curves\n",
        "- loss, val_loss\n",
        "- accuracy, val_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOfF8GeWU3zJ"
      },
      "outputs": [],
      "source": [
        "# 손실값을 그래프로 그린다. \n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['loss', 'val_loss'], loc = 'lower right')\n",
        "plt.show()\n",
        "\n",
        "# 정확도를 그래프로 그린다. \n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['accuracy', 'val_accuracy'], loc = 'lower right')\n",
        "plt.show()\n",
        "\n",
        "#############################################\n",
        "# More training graphs\n",
        "# More graphs of loss and accuracy\n",
        "# import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "\n",
        "history_dict = history.history \n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "plt.figure(figsize=(14, 4))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs, loss, 'go-', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'bd', label='Validation Loss')\n",
        "plt.plot(np.argmin(np.array(val_loss))+1,val_loss[np.argmin(np.array(val_loss))], 'r*', ms=12)\n",
        "plt.title('Training and Validation Loss, min: ' + str(np.round(val_loss[np.argmin(np.array(val_loss))],4)))\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "acc = history_dict['accuracy']\n",
        "val_acc = history_dict['val_accuracy']\n",
        "\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs, acc, 'go-', label='Training Accuracy') #, c='blue')\n",
        "plt.plot(epochs, val_acc, 'bd', label='Validation Accuracy') #, c='red')\n",
        "plt.plot(np.argmax(np.array(val_acc))+1,val_acc[np.argmax(np.array(val_acc))], 'r*', ms=12)\n",
        "plt.title('Training and Validation Accuracy, max: ' + str(np.round(val_acc[np.argmax(np.array(val_acc))],4)))\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "for images, labels in ds_test.take(1):  # Make a batch of images & labels\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(str(labels[i].numpy()) + \", \" + label_names[int(labels[i])])\n",
        "        plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNH22TxsU-zs"
      },
      "source": [
        "## Evaluation using test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drhL9Pk4U8pb"
      },
      "outputs": [],
      "source": [
        "y_pred0 = model.predict(ds_test)\n",
        "y_pred = np.argmax(y_pred0, axis=1)\n",
        "y_test = [labels.numpy() for _, labels in ds_test.unbatch()]\n",
        "print(\"정답=\", y_test[0])\n",
        "print(\"예측값=\", y_pred[0], np.argmax(y_pred0[0]))\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test, y_pred)\n",
        "# 0.9595\n",
        "\n",
        "#################################\n",
        "# Evaluate the model\n",
        "#################################\n",
        "model.evaluate(ds_test)  #,y_test)\n",
        "# loss: 1.1689 - accuracy: 0.6468\n",
        "# loss: 0.9207 - accuracy: 0.6799    # with dropout: 0.5\n",
        "# loss: 0.1658 - accuracy: 0.9595    # Transfer learning using EfficientNetB1\n",
        "# [0.20311422646045685, 0.9466000199317932]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "model.save('cifar10-TL-EfficientNetB1-Fine-Tuning.hdf5')"
      ],
      "metadata": {
        "id": "qR_e_Qrejoxd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}